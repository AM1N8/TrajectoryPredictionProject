{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce660a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vehicle Trajectory Prediction Using LiDAR and Ego Vehicle Data\n",
    "\n",
    "This notebook implements a trajectory prediction system that uses vehicle sensor data and LiDAR point clouds to predict the future path of a vehicle.\n",
    "\n",
    "## Initial Setup and Imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import glob\n",
    "from plyfile import PlyData\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Check TensorFlow version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# ## Custom Loss Function\n",
    "\n",
    "def weighted_displacement_loss(y_true, y_pred):\n",
    "    \"\"\"Custom loss function for displacement prediction with temporal weighting\"\"\"\n",
    "    # Extract delta_x and delta_y components\n",
    "    delta_x_true = y_true[:, :, 0]  # delta_x\n",
    "    delta_y_true = y_true[:, :, 1]  # delta_y\n",
    "    \n",
    "    delta_x_pred = y_pred[:, :, 0]  # delta_x\n",
    "    delta_y_pred = y_pred[:, :, 1]  # delta_y\n",
    "    \n",
    "    # Calculate distance error at each time step\n",
    "    distance_error = tf.sqrt(tf.square(delta_x_true - delta_x_pred) + tf.square(delta_y_true - delta_y_pred) + 1e-6)\n",
    "    \n",
    "    # Weight the errors - more weight on earlier predictions\n",
    "    time_steps = tf.shape(delta_x_true)[1]\n",
    "    time_weights = 1.0 / tf.sqrt(tf.cast(tf.range(1, time_steps + 1), tf.float32))\n",
    "    time_weights = time_weights / tf.reduce_sum(time_weights)  # Normalize\n",
    "    \n",
    "    # Apply the weights\n",
    "    weighted_error = distance_error * tf.expand_dims(time_weights, axis=0)\n",
    "    \n",
    "    # Reduce along time dimension\n",
    "    return tf.reduce_mean(weighted_error)\n",
    "\n",
    "# ## LiDAR Point Cloud Processing Functions\n",
    "\n",
    "def load_lidar_point_cloud(file_path):\n",
    "    \"\"\"Load LiDAR point cloud from PLY file\"\"\"\n",
    "    try:\n",
    "        plydata = PlyData.read(file_path)\n",
    "        x = plydata['vertex']['x']\n",
    "        y = plydata['vertex']['y']\n",
    "        z = plydata['vertex']['z']\n",
    "        intensity = plydata['vertex']['intensity']\n",
    "        \n",
    "        # Stack points and intensity\n",
    "        points = np.column_stack((x, y, z, intensity))\n",
    "        return points\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return np.zeros((100, 4))  # Return empty array if there's an error\n",
    "\n",
    "def sample_point_cloud(points, n_points=1024):\n",
    "    \"\"\"Sample a fixed number of points from point cloud with improved sampling strategy\"\"\"\n",
    "    if len(points) == 0:\n",
    "        return np.zeros((n_points, points.shape[1]))\n",
    "    \n",
    "    if len(points) >= n_points:\n",
    "        # Focus sampling on points closer to the vehicle (more relevant for trajectory)\n",
    "        # Calculate distance from origin (vehicle position)\n",
    "        distances = np.sqrt(points[:, 0]**2 + points[:, 1]**2)\n",
    "        \n",
    "        # Create probability weights - higher probability for closer points\n",
    "        # Add small constant to avoid division by zero\n",
    "        weights = 1.0 / (distances + 0.1)\n",
    "        weights /= np.sum(weights)  # Normalize\n",
    "        \n",
    "        # Sample points with weighted probability\n",
    "        indices = np.random.choice(len(points), n_points, replace=False, p=weights)\n",
    "        return points[indices]\n",
    "    else:\n",
    "        # If we have fewer points than needed, duplicate some points\n",
    "        indices = np.random.choice(len(points), n_points, replace=True)\n",
    "        return points[indices]\n",
    "\n",
    "def process_point_cloud(points, max_points=1024):\n",
    "    \"\"\"Process point cloud data with improved normalization\"\"\"\n",
    "    # Extract XYZ coordinates and intensity\n",
    "    xyz = points[:, :3]\n",
    "    \n",
    "    # Center points to origin\n",
    "    if len(xyz) > 0:\n",
    "        # Use robust centering - center to median rather than mean\n",
    "        center = np.median(xyz, axis=0)\n",
    "        xyz = xyz - center\n",
    "        \n",
    "        # Scale to unit sphere using 90th percentile instead of max\n",
    "        # This makes normalization more robust to outliers\n",
    "        radii = np.sqrt(np.sum(xyz**2, axis=1))\n",
    "        if len(radii) > 0:\n",
    "            scale = np.percentile(radii, 90)\n",
    "            if scale > 0:\n",
    "                xyz = xyz / scale\n",
    "    \n",
    "    # Include intensity as an additional feature, normalized to [0,1]\n",
    "    if points.shape[1] > 3:\n",
    "        intensity = points[:, 3].reshape(-1, 1)\n",
    "        if intensity.size > 0:\n",
    "            intensity_max = np.max(intensity) if np.max(intensity) > 0 else 1.0\n",
    "            intensity = intensity / intensity_max\n",
    "        processed_points = np.hstack((xyz, intensity))\n",
    "    else:\n",
    "        processed_points = xyz\n",
    "    \n",
    "    return processed_points\n",
    "\n",
    "# ## Data Processing Functions\n",
    "\n",
    "def map_timestamps_to_lidar(ego_df, lidar_path):\n",
    "    \"\"\"Map timestamps from ego data to LiDAR files with improved matching\"\"\"\n",
    "    lidar_files = glob.glob(os.path.join(lidar_path, 'lidar_*.ply'))\n",
    "    lidar_timestamps = [float(os.path.splitext(os.path.basename(f))[0].split('_')[1]) for f in lidar_files]\n",
    "    \n",
    "    # Sort timestamps for more efficient searching\n",
    "    lidar_timestamps = np.array(lidar_timestamps)\n",
    "    sorted_indices = np.argsort(lidar_timestamps)\n",
    "    lidar_timestamps = lidar_timestamps[sorted_indices]\n",
    "    lidar_files = [lidar_files[i] for i in sorted_indices]\n",
    "    \n",
    "    # Create mapping from ego timestamps to closest LiDAR timestamp\n",
    "    timestamp_to_lidar = {}\n",
    "    \n",
    "    for idx, ts in enumerate(ego_df['timestamp']):\n",
    "        # Find closest LiDAR timestamp using binary search\n",
    "        if len(lidar_timestamps) > 0:\n",
    "            closest_idx = np.searchsorted(lidar_timestamps, ts)\n",
    "            \n",
    "            # Handle edge cases\n",
    "            if closest_idx == 0:\n",
    "                closest_match = closest_idx\n",
    "            elif closest_idx == len(lidar_timestamps):\n",
    "                closest_match = closest_idx - 1\n",
    "            else:\n",
    "                # Compare distances to find the closest timestamp\n",
    "                if abs(lidar_timestamps[closest_idx] - ts) < abs(lidar_timestamps[closest_idx-1] - ts):\n",
    "                    closest_match = closest_idx\n",
    "                else:\n",
    "                    closest_match = closest_idx - 1\n",
    "                \n",
    "            timestamp_to_lidar[ts] = lidar_files[closest_match]\n",
    "    \n",
    "    return timestamp_to_lidar\n",
    "\n",
    "def calculate_vehicle_dynamics(ego_df):\n",
    "    \"\"\"Calculate enhanced vehicle dynamics features\"\"\"\n",
    "    # Copy dataframe to avoid modifying the original\n",
    "    df = ego_df.copy()\n",
    "    \n",
    "    # Calculate speed from velocity components\n",
    "    df['speed'] = np.sqrt(df['velocity_x']**2 + df['velocity_y']**2)\n",
    "    \n",
    "    # Calculate heading in radians (-π to π)\n",
    "    df['heading'] = np.arctan2(df['velocity_y'], df['velocity_x'])\n",
    "    \n",
    "    # Calculate acceleration components and magnitude\n",
    "    df['acceleration_x'] = df['velocity_x'].diff() / df['timestamp'].diff()\n",
    "    df['acceleration_y'] = df['velocity_y'].diff() / df['timestamp'].diff()\n",
    "    df['acceleration'] = np.sqrt(df['acceleration_x']**2 + df['acceleration_y']**2)\n",
    "    \n",
    "    # Calculate jerk (rate of change of acceleration)\n",
    "    df['jerk_x'] = df['acceleration_x'].diff() / df['timestamp'].diff()\n",
    "    df['jerk_y'] = df['acceleration_y'].diff() / df['timestamp'].diff()\n",
    "    df['jerk'] = np.sqrt(df['jerk_x']**2 + df['jerk_y']**2)\n",
    "    \n",
    "    # Calculate heading change rate (angular velocity)\n",
    "    df['heading_change'] = df['heading'].diff() / df['timestamp'].diff()\n",
    "    \n",
    "    # Calculate curvature (rate of change of heading with respect to distance)\n",
    "    # Avoid division by zero by adding a small constant\n",
    "    df['curvature'] = df['heading_change'] / (df['speed'] + 1e-6)\n",
    "    \n",
    "    # Identify whether the vehicle is effectively stationary\n",
    "    df['is_moving'] = (df['speed'] > 0.5).astype(float)\n",
    "    \n",
    "    # Fill NaN values\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in [np.float64, np.float32]:\n",
    "            df[col] = df[col].fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_relative_displacement(ego_df):\n",
    "    \"\"\"Calculate relative displacements instead of absolute positions\"\"\"\n",
    "    df = ego_df.copy()\n",
    "    \n",
    "    # Calculate displacement (delta) between consecutive frames\n",
    "    df['delta_x'] = df['x'].diff()\n",
    "    df['delta_y'] = df['y'].diff()\n",
    "    \n",
    "    # Fill NaN values with 0 (no movement)\n",
    "    df['delta_x'] = df['delta_x'].fillna(0)\n",
    "    df['delta_y'] = df['delta_y'].fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_and_segment_data(ego_df, min_speed=0.5, min_segment_length=5):\n",
    "    \"\"\"Filter stationary data and segment into meaningful driving sequences\"\"\"\n",
    "    df = ego_df.copy()\n",
    "    \n",
    "    # Mark segments with speed above threshold\n",
    "    df['is_moving'] = (df['speed'] > min_speed).astype(int)\n",
    "    df['movement_change'] = df['is_moving'].diff().abs()\n",
    "    df.loc[0, 'movement_change'] = 0  # Fix first row\n",
    "    \n",
    "    # Create segment IDs\n",
    "    df['segment_id'] = df['movement_change'].cumsum()\n",
    "    \n",
    "    # Get segment lengths\n",
    "    segment_lengths = df.groupby('segment_id').size()\n",
    "    valid_segments = segment_lengths[segment_lengths >= min_segment_length].index\n",
    "    \n",
    "    # Filter to only include valid segments\n",
    "    df_filtered = df[df['segment_id'].isin(valid_segments)].copy()\n",
    "    \n",
    "    # Reset segment_ids to be consecutive\n",
    "    segment_mapping = {old_id: new_id for new_id, old_id in enumerate(df_filtered['segment_id'].unique())}\n",
    "    df_filtered['segment_id'] = df_filtered['segment_id'].map(segment_mapping)\n",
    "    \n",
    "    # Create a binary column indicating if this is the first frame of a segment\n",
    "    df_filtered['segment_start'] = df_filtered['segment_id'].diff().ne(0).astype(int)\n",
    "    df_filtered.loc[df_filtered.index[0], 'segment_start'] = 1  # First row is always start of segment\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "# ## Sequence Preparation Functions\n",
    "\n",
    "def prepare_single_sequence(df_filtered, timestamp_to_lidar, current_idx, seq_length=10, \n",
    "                           scaler_input=None, input_features=None):\n",
    "    \"\"\"\n",
    "    Prepare a single sequence for prediction using relative displacement representation\n",
    "    \n",
    "    Args:\n",
    "        df_filtered: Processed ego vehicle data\n",
    "        timestamp_to_lidar: Mapping of timestamps to LiDAR files\n",
    "        current_idx: Index in the dataframe to use as the current position\n",
    "        seq_length: Length of the sequence to use as input\n",
    "        scaler_input: Trained scaler for input normalization\n",
    "        input_features: List of input features to use\n",
    "    \n",
    "    Returns:\n",
    "        sequence_input: Normalized sequence data\n",
    "        lidar_input: Processed LiDAR point cloud\n",
    "        start_position: (x, y) coordinates of the current position\n",
    "        start_heading: Current heading in radians\n",
    "    \"\"\"\n",
    "    if input_features is None:\n",
    "        input_features = [\n",
    "            'delta_x', 'delta_y',\n",
    "            'velocity_x', 'velocity_y', 'speed',\n",
    "            'heading', 'heading_change', 'curvature',\n",
    "            'acceleration_x', 'acceleration_y', 'acceleration',\n",
    "            'steering', 'throttle', 'brake',\n",
    "            'is_moving'\n",
    "        ]\n",
    "    \n",
    "    # Make sure we have enough history\n",
    "    if current_idx < seq_length:\n",
    "        print(f\"Warning: Not enough history at index {current_idx}. Need at least {seq_length} frames.\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Extract the sequence\n",
    "    seq_indices = range(current_idx - seq_length, current_idx)\n",
    "    input_seq = df_filtered.loc[seq_indices, input_features].values\n",
    "    \n",
    "    # Normalize the sequence\n",
    "    if scaler_input is not None:\n",
    "        input_seq_norm = scaler_input.transform(input_seq)\n",
    "    else:\n",
    "        input_seq_norm = input_seq\n",
    "        \n",
    "    # Get current position and heading\n",
    "    start_x = df_filtered.loc[current_idx - 1, 'x']\n",
    "    start_y = df_filtered.loc[current_idx - 1, 'y']\n",
    "    start_heading = df_filtered.loc[current_idx - 1, 'heading']\n",
    "    \n",
    "    # Get LiDAR data for the current timestep\n",
    "    current_ts = df_filtered.loc[current_idx - 1, 'timestamp']\n",
    "    if current_ts in timestamp_to_lidar:\n",
    "        lidar_file = timestamp_to_lidar[current_ts]\n",
    "        pointcloud = load_lidar_point_cloud(lidar_file)\n",
    "        sampled_points = sample_point_cloud(pointcloud)\n",
    "        processed_points = process_point_cloud(sampled_points)\n",
    "    else:\n",
    "        print(f\"Warning: No LiDAR data found for timestamp {current_ts}\")\n",
    "        processed_points = np.zeros((1024, 4))\n",
    "    \n",
    "    return input_seq_norm, processed_points, (start_x, start_y), start_heading\n",
    "\n",
    "# ## Trajectory Prediction Functions\n",
    "\n",
    "def convert_relative_to_absolute(start_x, start_y, relative_displacements):\n",
    "    \"\"\"Convert relative displacements to absolute positions\"\"\"\n",
    "    absolute_positions = np.zeros((len(relative_displacements) + 1, 2))\n",
    "    absolute_positions[0] = [start_x, start_y]\n",
    "    \n",
    "    for i in range(len(relative_displacements)):\n",
    "        absolute_positions[i+1, 0] = absolute_positions[i, 0] + relative_displacements[i, 0]\n",
    "        absolute_positions[i+1, 1] = absolute_positions[i, 1] + relative_displacements[i, 1]\n",
    "    \n",
    "    return absolute_positions\n",
    "\n",
    "def calculate_steering_from_path(future_positions, wheelbase=2.7):\n",
    "    \"\"\"Calculate steering angles from a predicted path using bicycle model\"\"\"\n",
    "    steering_angles = []\n",
    "    \n",
    "    for i in range(1, len(future_positions)):\n",
    "        # Calculate the displacement vector\n",
    "        dx = future_positions[i][0] - future_positions[i-1][0]\n",
    "        dy = future_positions[i][1] - future_positions[i-1][1]\n",
    "        \n",
    "        # Calculate the heading change\n",
    "        if i == 1:\n",
    "            # For the first point, assume the vehicle is already pointing in the direction of travel\n",
    "            heading_change = 0\n",
    "        else:\n",
    "            prev_dx = future_positions[i-1][0] - future_positions[i-2][0]\n",
    "            prev_dy = future_positions[i-1][1] - future_positions[i-2][1]\n",
    "            \n",
    "            # Calculate headings\n",
    "            prev_heading = math.atan2(prev_dy, prev_dx)\n",
    "            current_heading = math.atan2(dy, dx)\n",
    "            \n",
    "            # Calculate heading change (handle wrap-around)\n",
    "            heading_change = current_heading - prev_heading\n",
    "            if heading_change > math.pi:\n",
    "                heading_change -= 2 * math.pi\n",
    "            elif heading_change < -math.pi:\n",
    "                heading_change += 2 * math.pi\n",
    "        \n",
    "        # Calculate path radius using the bicycle model formula\n",
    "        # For small displacements, use a large radius to avoid extreme steering\n",
    "        displacement = math.sqrt(dx**2 + dy**2)\n",
    "        if abs(heading_change) < 1e-6 or displacement < 1e-3:\n",
    "            radius = float('inf')  # Straight line\n",
    "        else:\n",
    "            radius = displacement / heading_change  # Approximate radius of curvature\n",
    "        \n",
    "        # Calculate steering angle using the bicycle model (Ackermann steering)\n",
    "        if radius == float('inf'):\n",
    "            steering_angle = 0\n",
    "        else:\n",
    "            steering_angle = math.atan(wheelbase / radius)\n",
    "        \n",
    "        steering_angles.append(steering_angle)\n",
    "    \n",
    "    # For the first point, use the steering calculated for the second point\n",
    "    if steering_angles:\n",
    "        steering_angles.insert(0, steering_angles[0])\n",
    "    else:\n",
    "        steering_angles.append(0)  # Default to zero if we don't have enough points\n",
    "    \n",
    "    return steering_angles\n",
    "\n",
    "def predict_trajectory(model, sequence_input, lidar_input, start_position, scaler_target=None):\n",
    "    \"\"\"\n",
    "    Predict a future trajectory given current state\n",
    "    \n",
    "    Args:\n",
    "        model: Trained trajectory prediction model\n",
    "        sequence_input: Normalized sequence of recent vehicle dynamics\n",
    "        lidar_input: Processed LiDAR point cloud data\n",
    "        start_position: Tuple of (x, y) for current position\n",
    "        scaler_target: Scaler for target normalization\n",
    "    \n",
    "    Returns:\n",
    "        predicted_path: Array of absolute positions for the predicted path\n",
    "        steering_angles: Array of steering angles corresponding to the path\n",
    "    \"\"\"\n",
    "    # Expand dimensions for batch size\n",
    "    sequence_input = np.expand_dims(sequence_input, axis=0)\n",
    "    lidar_input = np.expand_dims(lidar_input, axis=0)\n",
    "    \n",
    "    # Get model prediction\n",
    "    prediction = model.predict([sequence_input, lidar_input])\n",
    "    \n",
    "    # Reshape prediction for inverse transformation\n",
    "    pred_reshaped = prediction.reshape(-1, 2)\n",
    "    \n",
    "    # Inverse transform to get real-world displacements\n",
    "    if scaler_target is not None:\n",
    "        pred_original = scaler_target.inverse_transform(pred_reshaped)\n",
    "    else:\n",
    "        pred_original = pred_reshaped\n",
    "    \n",
    "    # Reshape back\n",
    "    pred_original = pred_original.reshape(prediction.shape)[0]\n",
    "    \n",
    "    # Convert relative displacements to absolute positions\n",
    "    start_x, start_y = start_position\n",
    "    predicted_path = convert_relative_to_absolute(start_x, start_y, pred_original)\n",
    "    \n",
    "    # Calculate steering angles from the path\n",
    "    steering_angles = calculate_steering_from_path(predicted_path)\n",
    "    \n",
    "    return predicted_path, steering_angles\n",
    "\n",
    "# ## Visualization Functions\n",
    "\n",
    "def visualize_prediction(predicted_path, start_position, start_heading, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize a predicted trajectory\n",
    "    \n",
    "    Args:\n",
    "        predicted_path: Array of predicted positions\n",
    "        start_position: Tuple of (x, y) for starting position\n",
    "        start_heading: Starting heading in radians\n",
    "        save_path: Path to save the figure (if None, the figure is displayed)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Plot the predicted path\n",
    "    plt.plot(predicted_path[:, 0], predicted_path[:, 1], 'r-', linewidth=2, label='Predicted Path')\n",
    "    \n",
    "    # Mark starting position\n",
    "    start_x, start_y = start_position\n",
    "    plt.scatter(start_x, start_y, color='green', s=100, zorder=5, label='Current Position')\n",
    "    \n",
    "    # Draw an arrow indicating the starting heading\n",
    "    arrow_length = 2.0  # meters\n",
    "    dx = arrow_length * np.cos(start_heading)\n",
    "    dy = arrow_length * np.sin(start_heading)\n",
    "    plt.arrow(start_x, start_y, dx, dy, head_width=0.5, head_length=0.7, \n",
    "              fc='green', ec='green', zorder=5)\n",
    "    \n",
    "    # Mark points along the path\n",
    "    for i in range(1, len(predicted_path), 2):\n",
    "        plt.scatter(predicted_path[i, 0], predicted_path[i, 1], color='blue', s=30, alpha=0.7)\n",
    "    \n",
    "    # Add arrows to show direction\n",
    "    for i in range(1, len(predicted_path)-1, 2):\n",
    "        dx = predicted_path[i+1, 0] - predicted_path[i, 0]\n",
    "        dy = predicted_path[i+1, 1] - predicted_path[i, 1]\n",
    "        plt.arrow(predicted_path[i, 0], predicted_path[i, 1], dx*0.5, dy*0.5, \n",
    "                  head_width=0.3, head_length=0.5, fc='blue', ec='blue', alpha=0.5)\n",
    "    \n",
    "    # Set equal aspect ratio\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True)\n",
    "    plt.title('Predicted Vehicle Trajectory')\n",
    "    plt.xlabel('X Position (m)')\n",
    "    plt.ylabel('Y Position (m)')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Add distance markers\n",
    "    total_distance = 0\n",
    "    for i in range(1, len(predicted_path)):\n",
    "        dx = predicted_path[i, 0] - predicted_path[i-1, 0]\n",
    "        dy = predicted_path[i, 1] - predicted_path[i-1, 1]\n",
    "        segment_distance = np.sqrt(dx**2 + dy**2)\n",
    "        total_distance += segment_distance\n",
    "    \n",
    "    plt.figtext(0.02, 0.02, f'Total path distance: {total_distance:.2f} m', fontsize=10)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Visualization saved to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def predict_multiple_steps(model, ego_df, timestamp_to_lidar, start_idx, num_steps, \n",
    "                         seq_length, scaler_input, scaler_target, input_features, visualize=True):\n",
    "    \"\"\"\n",
    "    Predict trajectory for multiple consecutive steps, using previous predictions as input\n",
    "    for subsequent predictions\n",
    "    \n",
    "    Args:\n",
    "        model: Trained trajectory prediction model\n",
    "        ego_df: Processed ego vehicle data\n",
    "        timestamp_to_lidar: Mapping of timestamps to LiDAR files\n",
    "        start_idx: Index to start predictions from\n",
    "        num_steps: Number of consecutive prediction steps\n",
    "        seq_length: Length of input sequence for model\n",
    "        scaler_input: Scaler for input normalization\n",
    "        scaler_target: Scaler for target normalization\n",
    "        input_features: List of input features\n",
    "        visualize: Whether to visualize each prediction\n",
    "    \n",
    "    Returns:\n",
    "        List of predicted paths\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    current_idx = start_idx\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        print(f\"Predicting step {step+1}/{num_steps}\")\n",
    "        \n",
    "        # Prepare sequence for current position\n",
    "        seq_input, lidar_input, start_position, start_heading = prepare_single_sequence(\n",
    "            ego_df, timestamp_to_lidar, current_idx, seq_length, scaler_input, input_features\n",
    "        )\n",
    "        \n",
    "        if seq_input is None:\n",
    "            print(f\"Cannot predict at step {step+1}. Stopping.\")\n",
    "            break\n",
    "        \n",
    "        # Predict trajectory\n",
    "        predicted_path, steering_angles = predict_trajectory(\n",
    "            model, seq_input, lidar_input, start_position, scaler_target\n",
    "        )\n",
    "        \n",
    "        predictions.append({\n",
    "            'path': predicted_path,\n",
    "            'steering': steering_angles,\n",
    "            'start_position': start_position,\n",
    "            'start_heading': start_heading\n",
    "        })\n",
    "        \n",
    "        if visualize:\n",
    "            save_path = f\"prediction_step_{step+1}.png\"\n",
    "            visualize_prediction(predicted_path, start_position, start_heading, save_path)\n",
    "        \n",
    "        # Move to next position\n",
    "        current_idx += 1\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# ## Running Predictions\n",
    "\n",
    "# Example usage - load and run model on data\n",
    "def run_trajectory_prediction(data_path, model_path, scalers_path, seq_length=10, \n",
    "                             prediction_idx=None, num_predictions=1, visualize=True):\n",
    "    \"\"\"\n",
    "    Run trajectory prediction on new data\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to the directory containing ego data and LiDAR files\n",
    "        model_path: Path to the saved model file\n",
    "        scalers_path: Path to the saved scalers file\n",
    "        seq_length: Length of input sequence for model\n",
    "        prediction_idx: Specific index to predict (if None, will find a good segment)\n",
    "        num_predictions: Number of consecutive predictions to make\n",
    "        visualize: Whether to visualize predictions\n",
    "    \"\"\"\n",
    "    # Load model with custom loss function\n",
    "    print(f\"Loading model from {model_path}\")\n",
    "    model = keras.models.load_model(model_path, \n",
    "                                   custom_objects={'weighted_displacement_loss': weighted_displacement_loss})\n",
    "    \n",
    "    # Load scalers\n",
    "    print(f\"Loading scalers from {scalers_path}\")\n",
    "    with open(scalers_path, 'rb') as f:\n",
    "        scalers = pickle.load(f)\n",
    "        scaler_input = scalers['input_scaler']\n",
    "        scaler_target = scalers['target_scaler']\n",
    "    \n",
    "    # Load and process data\n",
    "    ego_data_file = glob.glob(os.path.join(data_path, 'ego_data_*.csv'))[0]\n",
    "    lidar_path = os.path.join(data_path, 'lidar')\n",
    "    \n",
    "    print(f\"Loading ego data from: {ego_data_file}\")\n",
    "    print(f\"Loading LiDAR data from: {lidar_path}\")\n",
    "    \n",
    "    # Load ego vehicle data\n",
    "    ego_df = pd.read_csv(ego_data_file)\n",
    "    print(f\"Loaded ego data with {len(ego_df)} timesteps\")\n",
    "    \n",
    "    # Process ego data\n",
    "    print(\"Processing ego vehicle data...\")\n",
    "    ego_df_dynamics = calculate_vehicle_dynamics(ego_df)\n",
    "    ego_df_relative = calculate_relative_displacement(ego_df_dynamics)\n",
    "    ego_df_filtered = filter_and_segment_data(ego_df_relative)\n",
    "    \n",
    "    print(f\"Filtered data contains {len(ego_df_filtered)} timesteps in \"\n",
    "          f\"{ego_df_filtered['segment_id'].nunique()} driving segments\")\n",
    "    \n",
    "    # Map timestamps to LiDAR files\n",
    "    print(\"Mapping timestamps to LiDAR files...\")\n",
    "    timestamp_to_lidar = map_timestamps_to_lidar(ego_df_filtered, lidar_path)\n",
    "    print(f\"Matched {len(timestamp_to_lidar)} timestamps to LiDAR files\")\n",
    "    \n",
    "    # Define input features\n",
    "    input_features = [\n",
    "        'delta_x', 'delta_y',\n",
    "        'velocity_x', 'velocity_y', 'speed',\n",
    "        'heading', 'heading_change', 'curvature',\n",
    "        'acceleration_x', 'acceleration_y', 'acceleration',\n",
    "        'steering', 'throttle', 'brake',\n",
    "        'is_moving'\n",
    "    ]\n",
    "    \n",
    "    # Choose prediction index\n",
    "    if prediction_idx is not None:\n",
    "        start_idx = prediction_idx\n",
    "    else:\n",
    "        # Find segments with good speed\n",
    "        segments = ego_df_filtered.groupby('segment_id')\n",
    "        good_segments = []\n",
    "        \n",
    "        for segment_id, segment_data in segments:\n",
    "            if len(segment_data) >= seq_length + 10 and segment_data['speed'].mean() > 3.0:\n",
    "                good_segments.append({\n",
    "                    'segment_id': segment_id,\n",
    "                    'start_idx': segment_data.index[seq_length],\n",
    "                    'avg_speed': segment_data['speed'].mean(),\n",
    "                    'length': len(segment_data)\n",
    "                })\n",
    "        \n",
    "        if good_segments:\n",
    "            # Sort by average speed (descending)\n",
    "            good_segments.sort(key=lambda x: x['avg_speed'], reverse=True)\n",
    "            best_segment = good_segments[0]\n",
    "            start_idx = best_segment['start_idx']\n",
    "            print(f\"Selected segment {best_segment['segment_id']} with avg speed {best_segment['avg_speed']:.2f} m/s\")\n",
    "        else:\n",
    "            # If no good segments found, use the middle of the first segment\n",
    "            first_segment = ego_df_filtered[ego_df_filtered['segment_id'] == 0]\n",
    "            start_idx = first_segment.index[min(seq_length, len(first_segment)-1)]\n",
    "            print(f\"No good segments found, using index {start_idx}\")\n",
    "    \n",
    "    print(f\"Starting predictions from index {start_idx}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = predict_multiple_steps(\n",
    "        model, ego_df_filtered, timestamp_to_lidar, \n",
    "        start_idx, num_predictions, \n",
    "        seq_length, scaler_input, scaler_target, \n",
    "        input_features, visualize\n",
    "    )\n",
    "    \n",
    "    # Print prediction results\n",
    "    for i, pred in enumerate(predictions):\n",
    "        print(f\"\\nPrediction {i+1}:\")\n",
    "        start_x, start_y = pred['start_position']\n",
    "        print(f\"  Starting position: ({start_x:.2f}, {start_y:.2f})\")\n",
    "        print(f\"  Starting heading: {math.degrees(pred['start_heading']):.2f} degrees\")\n",
    "        print(f\"  First steering angle: {math.degrees(pred['steering'][0]):.2f} degrees\")\n",
    "        print(f\"  Last steering angle: {math.degrees(pred['steering'][-1]):.2f} degrees\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# ## Example Usage with Parameters\n",
    "\n",
    "# This is an example of how you might run the code in a notebook environment\n",
    "# In a real notebook, you would set these parameters and run the cell\n",
    "'''\n",
    "# Set paths and parameters\n",
    "data_path = '/path/to/data'\n",
    "model_path = 'trajectory_prediction_model.h5'\n",
    "scalers_path = 'trajectory_scalers.pkl'\n",
    "seq_length = 10\n",
    "num_predictions = 3\n",
    "visualize = True\n",
    "\n",
    "# Run trajectory prediction\n",
    "predictions = run_trajectory_prediction(\n",
    "    data_path=data_path,\n",
    "    model_path=model_path,\n",
    "    scalers_path=scalers_path,\n",
    "    seq_length=seq_length,\n",
    "    prediction_idx=None,  # Auto-select a good segment\n",
    "    num_predictions=num_predictions,\n",
    "    visualize=visualize\n",
    ")\n",
    "\n",
    "# Analyze results\n",
    "for i, pred in enumerate(predictions):\n",
    "    # Plot the predicted path\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    path = pred['path']\n",
    "    plt.plot(path[:, 0], path[:, 1], 'b-', linewidth=2)\n",
    "    plt.scatter(path[0, 0], path[0, 1], color='green', s=100)\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True)\n",
    "    plt.title(f'Predicted Path {i+1}')\n",
    "    plt.xlabel('X Position (m)')\n",
    "    plt.ylabel('Y Position (m)')\n",
    "    plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "healthcare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
